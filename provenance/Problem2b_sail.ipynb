{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1784f201075efde80284adab9c0cafcf",
     "grade": false,
     "grade_id": "cell-9626fbe4254755a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## A few points:\n",
    "* Refer to the Datalog Assignment before attempting this notebook.\n",
    "* It's important to run following cell first for rest of notebook to work.\n",
    "* It's always a good idea to run cells in order. In case you have run cells in jumbled order and would want to start fresh, restart kernel from menu above.\n",
    "* All clingo cells start with `%%clingo`.\n",
    "* You can run your clingo cell against some basic facts and rules from a file. `set_db_file $filepath` sets the file against which your clingo cells will run.\n",
    "* Each clingo cell is independent of others. Rules defined in one cell won't be available in others.\n",
    "* It's nice to be able to execute clingo from within your notebook but don't forget to practice from command line. `%%clingo` is just a thin wrapper over command line and it's best to know how to use the underlying tool.\n",
    "* Upon assignment submission, we will run your code against different set of facts. Please don't hardcode answers and save yourself the embarassment.\n",
    "\n",
    "### Good luck!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ae668d919438b84edfc1469a898e4e68",
     "grade": false,
     "grade_id": "cell-6b2efd25bfdde520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Two retrospective provenance graphs of similar but different workflow (prospective provenance) graphs. While the resulting Hamming numbers are the same, the graphs reveal differences in the workflow executions, resulting in different provenance graphs (a) H1 (“Fish”) and (b) H3 (“Sail”).\n",
    "\n",
    "![Fish and Sail](fish_sail.png \"Fish and Sail\")\n",
    "\n",
    "\n",
    "\n",
    "# Problem 2b \"Sail\"\n",
    "\n",
    "Hints. \n",
    "1. Do Problem 2a first\n",
    "2. Your rules for fish graph from previous notebook should work as it is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "67dff3adbd452fe21e7e63f13d32cdd3",
     "grade": false,
     "grade_id": "cell-1ac836b26aa0290f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext lib.clingo.clingo_magic\n",
    "import os\n",
    "from lib.clingo.clingo_evaluate_util import clingo_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad21caeeeb605063a504445e06e908dc",
     "grade": false,
     "grade_id": "cell-5df58cbac7dd1e85",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# All clingo cells will run against this file containing some base facts.\n",
    "family_base_facts_and_rules_file = 'problem2-sail.lp'\n",
    "%set_db_file $family_base_facts_and_rules_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a98e6fd51ecc6c0ae76e8e23e70e5c52",
     "grade": false,
     "grade_id": "cell-1fb2450cb3f558dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "See the Hamming Rules Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f04bb6d82a784462d664e971781d2eb",
     "grade": false,
     "grade_id": "cell-9a253338d0f5be68",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"hamming\", \"predicate_arity\" : 3, \"result_var\": \"Hamming_test\"}\n",
    "% Hamming Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54a34a01e30e1489f90623a928f9ae04",
     "grade": false,
     "grade_id": "cell-c849268584ac952a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1. [10 points] Common Ancestor\n",
    "Compute the lineage of 360 in the sail graph, i.e., all nodes for which there is a path that leads to 360. Compare the output of same rule on fish graph. Note whether/how the lineage of 360 differs in the two graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f4dc7e58d6b5f910f5360fdb2298cdb4",
     "grade": false,
     "grade_id": "cell-afe5616b936b2cb6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"anc_360\", \"predicate_arity\" : 1, \"result_var\": \"Anc_360\"}\n",
    "\n",
    "% Change following expression.\n",
    "% add additional rules if necessary\n",
    "\n",
    "anc_360(X) :- replace_me(X).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c25cef70ca1546afffdd4a34b3973caf",
     "grade": false,
     "grade_id": "cell-9544bf36eff94e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Test 1 for Ancestor 360.\n",
    "Following test will compare output of your anc_360 rule against expected output.\n",
    "You must have run all clingo cells above for test to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5e12e830887c7147daff80e7127e0bd8",
     "grade": true,
     "grade_id": "cell-ce5a077866751446",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Following should be output of your previous cell.\n",
    "# Order of predicates in the output doesn't matter.\n",
    "# Run to see expected output with syntax highlighting.\n",
    "\n",
    "expected_output = '''\n",
    "anc_360(72) anc_360(24) anc_360(8) anc_360(4) anc_360(2) anc_360(1)\n",
    "'''\n",
    "db_file = 'problem2-sail.lp'\n",
    "clingo_evaluate(db_file, Anc_360['code'], 'anc_360', 1, expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "669261a9fca8408550dfb6b4f9321a91",
     "grade": true,
     "grade_id": "cell-05dab4d8baef1c99",
     "locked": true,
     "points": 9,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test\n",
    "# Omitted from student's version of notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "64d593a60248117246851f5dadafb9f1",
     "grade": false,
     "grade_id": "cell-d04550f0cad26927",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2. [20 points] Lowest Common Ancestor\n",
    "Compute lca(360,600,a), i.e., the lowest common ancestor of 360 and 600 for sail graph, i.e., all nodes for which there is\n",
    "a path that leads to 360. Note whether/how the lineage of 360 differs between Fish and Sail graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9a5f646bd335ef7252d3ac3e06473a5d",
     "grade": false,
     "grade_id": "cell-6e5820b7f20c3b0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"lca_360_600\", \"predicate_arity\" : 1, \"result_var\": \"Lca_360_600\"}\n",
    "\n",
    "% Change following expression.\n",
    "% add additional rules if necessary\n",
    "\n",
    "lca_360_600(X) :- replace_me(X).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4dcdc69173ed56f2cdd5e50bfe8eeb3",
     "grade": true,
     "grade_id": "cell-425251d8cc7c16e8",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_output = '''\n",
    "lca_360_600(24)\n",
    "'''\n",
    "db_file = 'problem2-sail.lp'\n",
    "clingo_evaluate(db_file, Lca_360_600['code'], 'lca_360_600', 1, expected_output)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "cs-513",
   "graded_item_id": "V166V",
   "launcher_item_id": "B5c7e",
   "part_id": "d0yeW"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
