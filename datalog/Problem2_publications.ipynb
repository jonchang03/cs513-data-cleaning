{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "019c14cac36a5b116679b38dda2b581c",
     "grade": false,
     "grade_id": "cell-c31b0281ede8d436",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# In this problem we will use publications dataset and write some datalog rules to check data integrity.\n",
    "\n",
    "## Few points:\n",
    "* Refer [Clingo with Jupyter Intro](Dlv_with_Jupyter_Intro.ipynb) before attempting this notebook.\n",
    "* It's important to run following cell first for rest of notebook to work.\n",
    "* It's always a good idea to run cells in order. In case you have run cells in jumbled order and would want to start fresh, restart kernel from menu above.\n",
    "* All clingo cells start with `%%clingo`.\n",
    "* You can run your clingo cell against some basic facts and rules from a file. `set_db_file $filepath` sets the file against which your clingo cells will run.\n",
    "* Each clingo cell is independent of others. Rules defined in one cell won't be available in others.\n",
    "* It's nice to be able to execute clingo from within your notebook but don't forget to practice from command line. `%%clingo` is just a thin wrapper over command line and it's best to know how to use the underlying tool.\n",
    "* Upon assignment submission, we will run your code against different set of facts. Please don't hardcode answers and save yourself the embarassment.\n",
    "\n",
    "### Good luck!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "875cee3adf4a9850107e54f9b3324399",
     "grade": false,
     "grade_id": "cell-aa25281cdb72aebe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext lib.clingo.clingo_magic\n",
    "import os\n",
    "from lib.clingo.clingo_evaluate_util import clingo_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82827069fcb839196eac68eb388e6011",
     "grade": false,
     "grade_id": "cell-852d315141b8fbde",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# All clingo cells will run against this file containing some base facts.\n",
    "publications_base_facts_and_rules_file = os.path.expanduser('~/data_readonly/datalog/publications_base.lp')\n",
    "%set_db_file $publications_base_facts_and_rules_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f9afb20fc1c6aaf87ab32bfc3ab6c98",
     "grade": false,
     "grade_id": "cell-b34ebb53f491fd07",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## We will now write various rules to find \"bad\" (inconsistent) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82efd091f85219c1a763423aba237984",
     "grade": false,
     "grade_id": "cell-c0c35d6badba74e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [10 points] The key attribute ID should uniquely determine all other attributes.\n",
    "\n",
    "In DENIAL form we report all IC violations, i.e., where there are at least two rows having the same ID same, but some differing attributes somewhere.\n",
    "Here we report both the name of the attribute and the duplicate values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "de002d4f519bcbd26e52ab0738becc22",
     "grade": false,
     "grade_id": "cell-ef096e8fda427628",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"icv_pid_key\", \"predicate_arity\" : 4, \"result_var\": \"Icv_pid_key\"}\n",
    "\n",
    "% Following code snippet and it's result will be assigned to local variable Icv_pid_key\n",
    "\n",
    "% Change following expressions.\n",
    "% In DENIAL form we report all IC violations, i.e., where there are at least two rows\n",
    "% having the same ID same, but some differing attributes somewhere.\n",
    "% Here we report both the name of the attribute and the duplicate values.\n",
    "icv_pid_key(ID,author,A1,A2) :-    replace_me_fd1(ID,A1,A2).\n",
    "icv_pid_key(ID,year,Y1,Y2) :-      replace_me_fd1(ID,Y1,Y2).\n",
    "icv_pid_key(ID,title,T1,T2) :-     replace_me_fd1(ID,T1,T2).\n",
    "icv_pid_key(ID,journal,J1,J2) :-   replace_me_fd1(ID,J1,J2).\n",
    "icv_pid_key(ID,vol,V1,V2) :-       replace_me_fd1(ID,V1,V2).\n",
    "icv_pid_key(ID,no,N1,N2) :-        replace_me_fd1(ID,N1,N2).\n",
    "icv_pid_key(ID,fp,F1,F2) :-        replace_me_fd1(ID,F1,F2).\n",
    "icv_pid_key(ID,lp,L1,L2) :-        replace_me_fd1(ID,L1,L2).\n",
    "icv_pid_key(ID,publisher,P1,P2) :- replace_me_fd1(ID,P1,P2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e4330db321b43dcd04d8be89b31e3123",
     "grade": false,
     "grade_id": "cell-e27a94260eb56dae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "#### [3 points] Test 1 for icv_pid_key.\n",
    "Following test will compare output of your icv_pid_key rule against expected output.\n",
    "You must have run all clingo cells above for test to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f54d4e8c238795676945f1e1cc7f90fe",
     "grade": true,
     "grade_id": "cell-6543256467863da4",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Following should be output of your previous cell.\n",
    "# Order of predicates in the output doesn't matter.\n",
    "# Run to see expected output with syntax highlighting.\n",
    "expected_output = '''\n",
    "icv_pid_key(4407,author,doe,kummel) icv_pid_key(4407,year,1969,2015) icv_pid_key(4407,title,ammonoids,foobar) icv_pid_key(4407,vol,10,137) icv_pid_key(4407,no,1,3) icv_pid_key(4407,fp,10,476) icv_pid_key(4407,lp,1,null) icv_pid_key(4407,publisher,null,publisher2)\n",
    "'''\n",
    "\n",
    "db_file = os.path.expanduser('~/data_readonly/datalog/publications_base.lp')\n",
    "clingo_evaluate(db_file, Icv_pid_key['code'], 'icv_pid_key', 4, expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23366df386665a6306eca74fec6598dc",
     "grade": false,
     "grade_id": "cell-5cd1b292d03f501f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "#### [7 points] Test 2 for icv_pid_key.\n",
    "Following is what is called a hidden test case. This will always pass in student's version but will actually be evaluated after submission.\n",
    "* We will first add some facts that are hidden from student.\n",
    "* We will run descendant rule using these new facts and see if rule still behaving correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d075938e5c4a3952ceb83dbe9f777a2",
     "grade": true,
     "grade_id": "cell-64b9c48e53c83dce",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will test the descendant with these new facts.\n",
    "# Contents of this cell will not be present in student's version of assignment.\n",
    "# This will only be evaluated after submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6bc64d1a18c9e8a6215eb2f8ca9482cb",
     "grade": false,
     "grade_id": "cell-77f229c9a55d2a5e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [10 points] Every journal has a single publisher, i.e., Journal --> Publisher\n",
    "In denial mode, we report the journals which have multiple publishers, two publishers at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2a84e100b8ad4f17996500ca97121517",
     "grade": false,
     "grade_id": "cell-3fb3e2c79c1b64ec",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"icv_journal_publisher\", \"predicate_arity\" : 3, \"result_var\": \"Icv_journal_publisher\"}\n",
    "\n",
    "% Following code snippet and it's result will be assigned to local variable Icv_journal_publisher\n",
    "\n",
    "% Food for thought: How are null values for publishers handled by your rules?\n",
    "% Do you notice different repair options, depending on whether or not a null value is reported?\n",
    "icv_journal_publisher(J,P1,P2) :- replace_me_fd2(J,P1,P2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "283d2d3c40ed388a92bbe17429aabe55",
     "grade": false,
     "grade_id": "cell-460a75b74e6f9681",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [3 points] Test 1 for icv_journal_publisher.\n",
    "Following test will compare output of your icv_journal_publisher rule against expected output.\n",
    "You must have run all clingo cells above for test to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7a1907fc2cf5a700a3c4e93663278d83",
     "grade": true,
     "grade_id": "cell-77630ccbfc9c2103",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Following should be output of your previous cell.\n",
    "# Order of predicates in the output doesn't matter.\n",
    "# Run to see expected output with syntax highlighting.\n",
    "expected_output = '''\n",
    "icv_journal_publisher(bullmcz,null,publisher1) icv_journal_publisher(bullmcz,publisher1,publisher2) icv_journal_publisher(bullmcz,null,publisher2)\n",
    "'''\n",
    "\n",
    "db_file = os.path.expanduser('~/data_readonly/datalog/publications_base.lp')\n",
    "clingo_evaluate(db_file, Icv_journal_publisher['code'], 'icv_journal_publisher', 3, expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8cd09919fa4c0feb493d50752010456b",
     "grade": false,
     "grade_id": "cell-5feae9607117e57a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### [7 points] Test 2 for icv_journal_publisher.\n",
    "Following is what is called a hidden test case. This will always pass in student's version but will actually be evaluated after submission.\n",
    "* We will first add some facts that are hidden from student.\n",
    "* We will run sibling rule using these new facts and see if rule still behaving correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3bb1d98012c92cf5892e1fc112cc7bab",
     "grade": true,
     "grade_id": "cell-18424b8a280f7092",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will test the icv_journal_publisher with these new facts.\n",
    "# Contents of this cell will not be present in student's version of assignment.\n",
    "# This will only be evaluated after submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7eb47663cfa016dd265edf4d6607381",
     "grade": false,
     "grade_id": "icv_person_has_parent_heading",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [10 points] The last page Lp cannot be smaller than the first page Fp.\n",
    "In DENIAL form, we report the ones for which last page is smaller than first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "75b80dca8a3a3a8594795a4f3a68fd6a",
     "grade": false,
     "grade_id": "cell-8cbc269071721973",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"icv_firstpage_lastpage\", \"predicate_arity\" : 3, \"result_var\": \"Icv_firstpage_lastpage\"}\n",
    "\n",
    "% Following code snippet and it's result will be assigned to local variable Icv_firstpage_lastpage\n",
    "\n",
    "% Change following expression.\n",
    "icv_firstpage_lastpage(ID,F,L) :- replace_me_nc1(ID,F,L).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "939771a33f721e2b2eb11d9923af3ad5",
     "grade": false,
     "grade_id": "cell-e8c336f26211c4b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "#### [3 points] Test 1 for icv_firstpage_lastpage.\n",
    "Following test will compare output of your icv_firstpage_lastpage rule against expected output.\n",
    "You must have run all clingo cells above for test to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "58fceb4ad0e393158af21a970c118762",
     "grade": true,
     "grade_id": "cell-59d604b47089f609",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Following should be output of your previous cell.\n",
    "# Order of predicates in the output doesn't matter.\n",
    "# Run to see expected output with syntax highlighting.\n",
    "expected_output = '''\n",
    "icv_firstpage_lastpage(6755,91,9) icv_firstpage_lastpage(4407,10,1)\n",
    "'''\n",
    "\n",
    "db_file = os.path.expanduser('~/data_readonly/datalog/publications_base.lp')\n",
    "clingo_evaluate(db_file, Icv_firstpage_lastpage['code'], 'icv_firstpage_lastpage', 3, expected_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "93a957635a0199f1289609211129ad50",
     "grade": false,
     "grade_id": "cell-7d1799d48e527c6e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "#### [7 points] Test 2 for icv_firstpage_lastpage.\n",
    "Following is what is called a hidden test case. This will always pass in student's version but will actually be evaluated after submission.\n",
    "* We will first add some facts that are hidden from student.\n",
    "* We will run icv_person_has_parent rule using these new facts and see if rule still behaving correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d81d59f0858763537fe36379a57a02f",
     "grade": true,
     "grade_id": "cell-88204f90e3e2a1f9",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will test the icv_person_has_parent with these new facts.\n",
    "# Contents of this cell will not be present in student's version of assignment.\n",
    "# This will only be evaluated after submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7414e525811f1d28f6b12f19afa13ef3",
     "grade": false,
     "grade_id": "cell-ab38d3ab673eb721",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [10 points] Inclusion Dependency: Every cited publication in CITES also occurs in PUBLICATION.\n",
    "\n",
    "In DENIAL form, we report those publications which are in CITES but not in PUBLICATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dbc81371fae1e814f0f681de65977173",
     "grade": false,
     "grade_id": "cell-b02a72ef73f7eff2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"icv_cited_publication\", \"predicate_arity\" : 1, \"result_var\": \"Icv_cited_publication\"}\n",
    "\n",
    "% Following code snippet and it's result will be assigned to local variable Icv_cited_publication\n",
    "\n",
    "% Change following expression.\n",
    "%(Inclusion Dependency): Every cited publication in CITES also occurs in PUBLICATION.\n",
    "icv_cited_publication(P2) :- replace_me_id(P2).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2bd3bea699769ca80bb765a1d439ab0",
     "grade": false,
     "grade_id": "cell-10e3eee48295cf85",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### [3 points] Test 1 for icv_cited_publication.\n",
    "Following test will compare output of your icv_person_has_father_mother rule against expected output.\n",
    "You must have run all clingo cells above for test to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da1068d08dbd9b5a99037a9271fa5bbb",
     "grade": true,
     "grade_id": "cell-beda52bb72ea0c56",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Following should be output of your previous cell.\n",
    "# Order of predicates in the output doesn't matter.\n",
    "# Run to see expected output with syntax highlighting.\n",
    "expected_output = '''\n",
    "icv_cited_publication(2020) icv_cited_publication(3799)\n",
    "'''\n",
    "\n",
    "db_file = os.path.expanduser('~/data_readonly/datalog/publications_base.lp')\n",
    "clingo_evaluate(db_file, Icv_cited_publication['code'], 'icv_cited_publication', 1, expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "81c931869319ef2b575af9e28f7afc57",
     "grade": false,
     "grade_id": "cell-b875153ef89aa363",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "#### [7 points] Test 2 for icv_cited_publication.\n",
    "Following is what is called a hidden test case. This will always pass in student's version but will actually be evaluated after submission.\n",
    "* We will first add some facts that are hidden from student.\n",
    "* We will run icv_person_has_father_mother rule using these new facts and see if rule still behaving correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2f50a407282f79b6a5b2614297c40bc",
     "grade": true,
     "grade_id": "cell-72ee4e65be8e3a76",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will test the icv_cited_publication with these new facts.\n",
    "# Contents of this cell will not be present in student's version of assignment.\n",
    "# This will only be evaluated after submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e4c099cac1007d11d3cefd88f60969c",
     "grade": false,
     "grade_id": "cell-cb1c92bbcc197fbe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [10 points] If P1 cites P2 then P2's year of publication cannot be greater than P1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84e4108a2e35a50c92d90166710eecec",
     "grade": false,
     "grade_id": "cell-22f12beeb693f8b0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%clingo {\"predicate\" : \"icv_p1_greater_p2\", \"predicate_arity\" : 4, \"result_var\": \"Icv_p1_greater_p2\"}\n",
    "\n",
    "% Following code snippet and it's result will be assigned to local variable Icv_p1_greater_p2\n",
    "\n",
    "% Change following expression.\n",
    "icv_p1_greater_p2(P1,P2,Y1,Y2) :- replace_me_nc2(P1,P2,Y1,Y2).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "439bf9cfff2ff93d4190c3866efcd834",
     "grade": false,
     "grade_id": "cell-089e9ca45b5d0424",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### [3 points] Test 1 for icv_p1_greater_p2.\n",
    "Following test will compare output of your icv_p1_greater_p2 rule against expected output.\n",
    "You must have run all clingo cells above for test to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06d0334d30b98ce6722ab627836c7396",
     "grade": true,
     "grade_id": "cell-14c3ff901459371a",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Following should be output of your previous cell.\n",
    "# Order of predicates in the output doesn't matter.\n",
    "# Run to see expected output with syntax highlighting.\n",
    "expected_output = '''\n",
    "icv_p1_greater_p2(2044,2580,1934,1962)\n",
    "'''\n",
    "\n",
    "db_file = os.path.expanduser('~/data_readonly/datalog/publications_base.lp')\n",
    "clingo_evaluate(db_file, Icv_p1_greater_p2['code'], 'icv_p1_greater_p2', 4, expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9ede9502cc77eb4bed32deee3eee103d",
     "grade": false,
     "grade_id": "cell-3848a0480f3942af",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### [7 points] Test 2 for icv_p1_greater_p2.\n",
    "Following is what is called a hidden test case. This will always pass in student's version but will actually be evaluated after submission.\n",
    "* We will first add some facts that are hidden from student.\n",
    "* We will run icv_person_has_father_mother rule using these new facts and see if rule still behaving correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be1982984396cc03b28f9cf3bdb8bf70",
     "grade": true,
     "grade_id": "cell-74b74609489abaa1",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will test the icv_p1_greater_p2 with these new facts.\n",
    "# Contents of this cell will not be present in student's version of assignment.\n",
    "# This will only be evaluated after submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "cs-513",
   "graded_item_id": "6KgR1",
   "launcher_item_id": "Vg9Le",
   "part_id": "wAHUL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
